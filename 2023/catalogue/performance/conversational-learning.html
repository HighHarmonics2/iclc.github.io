
<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
	<link href="https://fonts.googleapis.com/css2?family=Exo:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
	<!-- Font Awesome icons (free version)-->
	<script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
	<!-- Core theme CSS (includes Bootstrap)-->
	<link href="https://iclc.toplap.org/2023/css/styles.css" rel="stylesheet" />

	<meta property="og:title" content="ICLC 2023 - Catalogue - Conversational Learning" />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://iclc.toplap.org/2023/catalogue/performance/conversational-learning.html" />
    <meta property="og:description" content="ICLC2023 Catalogue - International Conference on Live Coding" />

    <meta property="og:image" content="https://iclc.toplap.org/2023/assets/img/open-graph.png" />
    <meta property="og:image:type" content="image/png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta property="og:locale" content="en_US" />   

    <base href="/2023/" />

	<title>ICLC2023 Catalogue - Conversational Learning</title>

    <style>
		p.list-header {
			margin-bottom: 5px;
		}

		td {
			vertical-align: top;
			padding-bottom: 20px;
			padding-right: 40px;
      	}

		h4 {
			margin-top: 35px;
		}

		table {
			width: 100%;
		}

		h2 {
			text-transform: none;
		}

		.catalogue p {
			margin-bottom: 1rem !important;
		}

    </style>
</head>
<body id="page-top">
	<!-- Generate the main menu bar -->
	<script src="https://iclc.toplap.org/2023/js/scripts-extension.js?cachebust=9944"></script>
	<script>makeMenu();</script>

	<section class="about-section catalogue" >
		<div class="container px-4 px-lg-5">
			<div class="row gx-4 gx-lg-5 justify-content-center">
				<div class="col-lg-8">
                    <a href="catalogue/" style="text-decoration: none;"><h6 style="margin-bottom:25px; margin-top: 20px; text-decoration: none;">ICLC 2023 Catalogue</h6></a>
                    <h2 style="margin-bottom: 15px;">Conversational Learning</h2>
                    
        <p><strong>Iván&nbsp;Paz</strong></p>
        <p class="list-header">Will be performed at:</p>
        <ul>
            <li><a href='catalogue/event/immersed-in-code.html'>
        <strong>Immersed in Code</strong><br>
        Friday, April 21st, Pre-Show 19:30 / Show: 20:00, <em>Former Pieter Baan Centrum</em>
    </a></li>
        </ul>
        <h4>Program Notes</h4>
        <p>Conversational learning explores live coding liveness within the machine learning 
process (data collection, training and validation), focusing on how real-time 
training of a machine learning algorithm can be sonically exposed. It is based on
a rule-learning algorithm that automatically produces new synthesizer presets out 
of a small labeled database. The algorithm is designed with only two parameters 
controlling “how close” the new created presets can be from those originally present
in the training data. The learning process happens mid-performance, tweaking the 
algorithm parameters on-the-fly. Then, the different learned models unfold the piece
in conversation with the performer.</p>
        <h4>Abstract</h4><p><em><br>The abstract is displayed here for proof-reading and will only be part of the published proceedings, not of the final version of this web catalogue.</em></p><p>Conversational learning explores live coding liveness within the machine learning
process (data collection, training and validation), focusing on how the real-time
training of a machine learning algorithm can be sonically exposed. It is based on
a rule-learning algorithm that automatically produces new synthesizer presets out
of a small labeled database. The algorithm is designed with only two parameters
(I did that on purpose) controlling “how close” the new created presets can
be from those originally present in the training data. The learning process
happens mid-performance, tweaking the algorithm parameters on-the-fly. Then,
the different learned models unfold the piece in conversation with the performer.</p>
<p>For example, it is possible to have a model that replicates the training data or to
extract 700 -to say a number- new variations with the risk of having unpleasant
surprises. The performance starts form scratch and the data labels are used to
conduct the sections and the sound moments of the performance. The sound
synthesis is carried out in SuperCollider and the syntax looks like:</p>
<p><strong><em>ruler data.csv distance:4 consistency:0.5</em></strong></p>
<p><strong><em>~set.value(Ndef(\x),~rules,‘r’,‘rain’)</em></strong></p>
<p>In the first function, ruler is the algorithm (stands for rule learning), data.csv
is the training dataset, distance and consistency together control the induction
process. In the second function we specify
the Synth, the rules from which the new preset is taken, the number of preset
(in case we want) and the label or class. For this performance I will focus on
training different models mid-performance. (I normally train some models but
this has not been the main focus.)</p>
    
				</div>
			</div>
		</div>
	</section>

	<!-- Generate contacs and copyright footer -->
	<script>
		socials();
		footer();
	</script>

	<!-- Bootstrap core JS-->
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
	<!-- Core theme JS-->
	<script src="https://iclc.toplap.org/2023/js/scripts.js"></script>
	<script src="https://cdn.startbootstrap.com/sb-forms-latest.js"></script>
</body>
</html>