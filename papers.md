---
title: Papers
category: papers
layout: default
---

The full proceedings will be available shortly, in the meantime you
can read the abstracts below.

<div id="paper5" class="paper">

<h2 class="title">Live Coding and Machine Listening</h2>

Nick Collins (Durham University, Department of Music)<br />


<h3 class="abstract">Abstract</h3>
Live coding control of machine listening processes, or more radically, machine listening control of live coding, provides an exciting area of crossover between two research frontiers in computer music. This article surveys the state of the art, and reports a number of experimental projects that point to potentially productive further directions.
</div>

<hr />
<div id="paper72" class="paper">

<h2 class="title">Embodiment of code</h2>

Marije Baalman (nescivi)<br />


<h3 class="abstract">Abstract</h3>
<p>The code we read on the screens of a livecoding performance is an expression of our compositional concepts. In this paper I reflect on the practice of livecoding from the concept of embodiment as proposed by <span class="citation">Varela, Thompson, and Rosch (1991)</span>: how we as coders embody the code, how machines can embody code, and how we inevitably need to deal with the physicality of the machines and our own bodies that we use in our performances, and how we adapt both our machines and bodies to enable our performances.</p>
</div>

<hr />
<div id="paper76" class="paper">

<h2 class="title">Performative Code: Strategies for Live Coding Graphics</h2>

Shawn Lawson (Rensselaer Polytechnic Institute)<br />


<h3 class="abstract">Abstract</h3>
<p>Performing real-time, live coded graphics requires a streamlined programming environment, efficient implementation techniques, improvisatory inventiveness, a tuned ear, and above all, aesthetic sensibility. The performer must not only pull together these concepts, but maintain an awareness and forethought, of the graphical results of and performance expectations of the live coding environment.</p>
</div>

<hr />
<div id="paper79" class="paper">

<h2 class="title">Live Writing: Asynchronous Playback of Live Coding and Writing</h2>

Sang Won Lee (University of Michigan, Ann Arbor)<br />Georg Essl (University of Michigan, Ann Arbor)<br />


<h3 class="abstract">Abstract</h3>
<p>We introduce Live Writing, asynchronous playback of a live coding performance or, more generally, writing. The concept of Live Writing is realized in a web-based application which logs every keystroke that a writer makes and let the writing later playable by the audience or the readers in real-time. The goal of Live Writing is twofold. One, it aims to support collaboration between musicians by reproducing a live coding performance based on keystroke data logged in the platform. This offers a new way for a live coder to archive live coding music and to communicate with others in asynchronous fashion. Two, it aims to transform written communication into a real-time experience so that a writer can display a writing to readers in a real-time manner as if it is being typed in front of the readers. We explain the design and the implementation of the system and demonstrate two different use cases of the system: live coding and writing.</p>
</div>

<hr />
<div id="paper83" class="paper">

<h2 class="title">Approximate Programming: Coding Through Gesture and Numerical Processes</h2>

Chris Kiefer (Department of Informatics, University of Sussex, UK.)<br />


<h3 class="abstract">Abstract</h3>
Approximate programming is a novel approach to live coding that augments traditional programming methods with methods of generating and editing code through realtime numerical processes, using an underlying system that employs representations and transformations from gene expression programming. It aims to provide a hybrid environment where code can be created and modified expressively with multiparametric controllers, and well as with conventional text editing tools. It does this while aiming to keep the code as the central point of representation in the system. Two case studies are presented where the system has been used in live performance for musical improvisation and then for generative audiovisualisation. Initial trials of the system highlight its strengths as an embodied method for control of complex code structures, and as a novel method for combining low-level conceptual structures into higher-level forms. The case studies show two key limitations of the system, with challenges in comprehension of the final code output in text form, and difficulties arising from the highly nonlinear nature of the input-output mappings. Initials solutions are presented in the form of a GUI system for interacting with code in tree representation form.
</div>

<hr />
<div id="paper84" class="paper">

<h2 class="title"><p>Copy-Paste Tracking: Fixing Spreadsheets Without Breaking Them</p></h2>

Felienne Hermans (Delft University of Technology)<br />Tijs van der Storm (Centrum Wiskunde &amp; Informatica)<br />


<h3 class="abstract">Abstract</h3>
<p>Spreadsheets are the most popular live programming environments, but they are also notoriously fault-prone. One reason for this is that users actively rely on copy-paste to make up for the lack of abstraction mechanisms. Adding abstraction however, introduces indirection and thus cognitive distance. In this paper we propose an alternative: copy-paste tracking. Tracking copies that spreadsheet users make, allows them to directly edit copy-pasted formulas, but instead of changing only a single instance, the changes will be propagated to all formulas copied from the same source. As a result, spreadsheet users will enjoy the benefits of abstraction without its drawbacks.</p>
</div>

<hr />
<div id="paper95" class="paper">

<h2 class="title">Live Patch / Live Code</h2>

Charles Celeste HUTCHINS (University of Kent)<br />


<h3 class="abstract">Abstract</h3>
<p>Modular synthesiser live-patching has gradually been accepted into the big-tent of live coding practice, due to a number of natural similarities to computer-based live coding. These similarities especially include flexibility, complexity and sudden stops. In my own performance of live-patching, I have sought out other areas of digital live coding practice to apply to the modular synthesiser. These include starting from a blank slate, showing my cables (sometimes with projection), graph changes and the use of conditional triggers to create audio events.</p>
</div>

<hr />
<div id="paper96" class="paper">

<h2 class="title">SuperCopair: Collaborative Live Coding on SuperCollider through the cloud</h2>

Antonio Deusany de Carvalho Junior (Universidade de São Paulo)<br />Sang Won Lee (University of Michigan)<br />Georg Essl (University of Michigan)<br />


<h3 class="abstract">Abstract</h3>
<p>In this work we present the SuperCopair package, which is a new way to integrate cloud computing into a collaborative live coding scenario with minimum efforts in the setup. This package, created in Coffee Script for Atom.io, is developed to interact with SuperCollider and provide opportunities for the crowd of online live coders to collaborate remotely on distributed performances. Additionally, the package provides the advantages of cloud services offered by Pusher. Users can share code and evaluate lines or selected portions of code on computers connected to the same session, either at the same place and/or remotely. The package can be used for remote performances or rehearsal purposes with just an Internet connection to share code and sounds. In addition, users can take advantage of code sharing to teach SuperCollider online or fix bugs in the algorithm.</p>
</div>

<hr />
<div id="paper99" class="paper">

<h2 class="title">very long cat: zero-latency network music with live coding</h2>

David Ogborn (McMaster University)<br />Shawn Mativetsky (CIRMMT, Schulich School of Music, McGill University)<br />


<h3 class="abstract">Abstract</h3>
<p>very long cat are a new network music duo combining tabla and live coding, rehearsing and performing via the Internet, and employing an eclectic range of techniques and technologies. The specific structure of the ensemble’s network music setup, with one musician live coding and monitoring their own performance with a calibrated delay, allows both musicians to experience each other’s performances as synchronized. This poster focuses on the evolving technical configuration of this hybrid ensemble, with an emphasis on the constraints imposed by the insistence on “zero latency” in a live coding ensemble (some sound transformations are not feasible, and others are implemented in a characteristic way).</p>
</div>

<hr />
<div id="paper100" class="paper">

<h2 class="title">extramuros: making music in a browser-based, language-neutral collaborative live coding environment</h2>

David Ogborn (McMaster University)<br />Eldad Tsabary (Concordia University)<br />Ian Jarvis (McMaster University)<br />Alexandra Cárdenas (University of the Arts in Berlin)<br />Alex McLean (University of Leeds)<br />


<h3 class="abstract">Abstract</h3>
<p>The extramuros software was developed to explore live coding and network music, bringing live coding musicians together around shared text buffers. Originally developed to support a globally distributed live coding ensemble, the extramuros software has found additional application in projecting laptop orchestra performances to remote sites, in zero-installation workshop and performance settings, and in facilitating the efficient display of code by an ensemble. As the software works by connecting shared text buffers to audio programming languages through specific network connections augmented by pipes, it is a language-neutral approach. This paper describes the overall architecture of the extramuros system, relating that architecture to perennial network music concerns for bandwidth, security, and synchronization. Examples of early use in workshops, rehearsals and performances by laptop orchestras and other small telematic ensembles are discussed, leading to a concluding discussion of directions for future work.</p>
</div>

<hr />
<div id="paper101" class="paper">

<h2 class="title">Deadmau5, Derek Bailey, and the Laptop Instrument -- Improvisation, Composition, and Liveness in Live Coding</h2>

Adam Parkinson (EAVI, Goldsmiths)<br />Renick Bell (Tama Art University)<br />


<h3 class="abstract">Abstract</h3>
<p>Dance music superstar Deadmau5 and the improvising guitarist Derek Bailey represent, through their writing and practice, two very different approaches to performing live. By critically considering the practice of live coding in relation to these divergent approaches, we discuss live coding with regards to where the liveness lies and how the laptop and software are treated as a musical instrument. Each practice uses the laptop as a musical tool in a very different way. Live coding uses the laptop as an instrument in a manner that draws upon the techniques and strategies of free improvisation, in contrast to Deadmau5’s notion of laptop as playback device and the live performance as spectacle. We discuss Deadmau5’s practice in relation to Francisco Lopez’s notion of the possibilities of electronic performance, and ideas about labour and liveness.</p>
</div>

<hr />
<div id="paper102" class="paper">

<h2 class="title">Sharing Time and Code in a Browser-Based Live Coding Environment</h2>

Charlie Roberts (University of California at Santa Barbara)<br />Karl Yerkes (University of California at Santa Barbara)<br />Danny Bazo (University of California at Santa Barbara)<br />Matthew Wright (University of California at Santa Barbara)<br />JoAnn Kuchera-Morin (University of California at Santa Barbara)<br />


<h3 class="abstract">Abstract</h3>
<p>We describe research extending the live coding environment Gibber with affordances for ensemble, networked, live coding performances. These include shared editing of code documents, remote code execution, an extensible chat system, shared state, and clock synchronization via proportional-integral control. We discuss these features using the framework provided by Lee and Essl in their 2014 paper <em>Models and Opportunities for Networked Live Coding</em>.</p>
</div>

<hr />
<div id="paper104" class="paper">

<h2 class="title"><strong>def</strong> Gribber = (Grace + Gibber)</h2>

Timothy Jones (Victoria University of Wellington, NZ)<br />James Noble (Victoria University of Wellington, NZ)<br />


<h3 class="abstract">Abstract</h3>
<p>Grace is a new object-oriented education programming language that we are designing. One of the Grace implementations, Hopper, is an interpreter that runs on top of JavaScript. Gibber is series of libraries that support real-time audio processing, and also a simple livecoding interactive development environment, also on top of JavaScript. In this demonstration, we will present Gribber, a web-based IDE that incorporates the Hopper interpreter into the Gibber IDE, and so gives Grace live access to the Gibber audio libraries. Because of Hopper's continuation-passing design, Gribber programs can appear multi-threaded, apparently running one or more loops in parallel, each pseudo-thread generating sound and graphics in simultaneously. We will demonstrate how Gribber can be used for <em>BALSA</em>-style algorithm animation, and <em>Sorting Out Sorting</em> style algorithm races.</p>
</div>

<hr />
<div id="paper106" class="paper">

<h2 class="title">Physical Livecoding with littleBits</h2>

James Noble (Victoria University of Wellington, NZ)<br />


<h3 class="abstract">Abstract</h3>
<p>littleBits (littleBits.cc) is an open-source hardware library of pre-assembled analogue components that can be easily assembled into circuits, disassembled, reassembled, and re-used. In this demonstration, we will show how littleBits --- and the KORG littleBits SynthKit in particular --- can be considered a physically-embodied domain specific programming language, and thus how assembling or improvising music with littleBits circuits is a tangible form of livecoding.</p>
</div>

<hr />
<div id="paper110" class="paper">

<h2 class="title">TextAlive Online: Live Programming of Kinetic Typography Videos with Online Music</h2>

Jun Kato, Tomoyasu Nakano, Masataka Goto (National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan)<br />


<h3 class="abstract">Abstract</h3>
<p>This paper introduces a web-based integrated design environment named &quot;TextAlive Online&quot; that supports creating Kinetic Typography videos synchronized with songs available online. It is the hybrid of a content authoring tool and a live programming environment. Through its development, we investigate the interaction design that most benefits from the interactive user interfaces used by designers and programmers, as well as the collaborative nature of the open-source culture on the web. This system is accessible at <a href="http://textalive.jp">textalive.jp</a> and the interactive &quot;live&quot; version of this paper is available at <a href="http://textalive.jp/paper">textalive.jp/paper</a>.</p>
</div>

<hr />
<div id="paper94"><h2 class="title"> Livesolving: Enabling Collaborative Problem Solvers to Perform at Full Capacity</h2><table class="authorlist"><tr><td>Steven Tanimoto (University of Washington)</td></tr></table><h3 class="abstract">Abstract</h3>Collaborative problem solving is a key methodology for tackling complex and/or contentious problems. The methodology is supported by computer and communication systems that bring human solvers together with computational agents and provide clear protocols for exploring and rating alternative solution approaches. However, these systems can be challenging to use due not only to the complexity of the problems being solved but the variety of abstractions involved in managing the solution process, e.g., problem representations, collaborations, and strategies. This paper offers new ideas to help the human users of such systems to learn and work more effectively. It also suggests how problem solving may sometimes be carried out in performance contexts similar to those of livecoding improvisational music. Most important here is the identification of seven forms of liveness in problem solving that may heighten a solving team’s sense of engagement. Common themes among them are increasing solvers’ awareness and minimizing latency between solver intentions and system responses. One of the seven livesolving forms involves solvers in tracing paths within problem-space graphs. This and the other six forms derive from experience with a system called CoSolve, developed at the University of Washington.</div><hr /><div id="paper73"><h2 class="title"> Craft Practices of Live Coding Language Design</h2><table class="authorlist"><tr><td>Alan Blackwell (University of Cambridge) and Samuel Aaron (University of Cambridge)</td></tr></table><h3 class="abstract">Abstract</h3>This paper reflects on the development process of two Live Coding languages, Blackwell’s Palimpsest and Aaron’s Sonic Pi, from the perspective of practice-led arts and craft research. Although informed by prior research in education, music, end-user programming and visual languages, these projects do not apply those principles through conventional software engineering processes or HCI techniques. As is often the case with practice-led research, the development process itself provides an opportunity for reflection on the nature of software as a craft – both for live-coding researchers, and for users of the live-coding systems that we create. In reflecting, we relate our own practice to recent perspectives on software as material, and on the role of craft as an element of interaction design research. The process that we have followed to support this analysis could be applied by other developers wishing to engage in similar reflection.</div><hr /><div id="paper89"><h2 class="title"> Pietro Grossi's live coding</h2><table class="authorlist"><tr><td>Giovanni Mori (University of Florence)</td></tr></table><h3 class="abstract">Abstract</h3>Pietro Grossi has been one of the first pioneers in computer music in Italy. His work, however, is still quite underconsidered because his art’s concepts was judged utopistic, without a connection with contemporary cultural manifestations and harshly anti-academic. Instead, in my opinion, it seems to be now the right moment to revalue his work, in order to understand from where some computer music practices have their roots. In this article, I compare the concepts and the work methods developed by Grossi to those employed by live coders. My aim is to demonstrate that the Italian composer’s concepts were not only ahead of his time but also anticipatory of future developments. </div><hr /><div id="paper68"><h2 class="title"> Live Coding the computer as part of a free improvisation orchestra of acoustic instruments</h2><table class="authorlist"><tr><td>Antonio Goulart (University of Sao Paulo) and Miguel Antar (University of Sao Paulo)       </td></tr></table><h3 class="abstract">Abstract</h3>In this paper we present our experience of having a live coder amongst acoustic musicians in a free improvisation orchestra. The acoustic musicians in the orchestra had no previous experience with live coding. We will discuss all the difficulties we experienced and the process for overcoming them, illustrating our observations with audio excerpts from some of our recorded sessions. We will also go through a discussion about the nature of the instruments and raise the question of how deeply the musicians should understand code in order to effectively interact in the free improvisation context. Finally we propose a piece for live coder and orchestra that artificially explores the different dimensions of an orchestra session.</div><hr /><div id="paper88"><h2 class="title"> Analysing Live Coding with Ethnographical Approach</h2><table class="authorlist"><tr><td>Giovanni Mori (University of Florence)</td></tr></table><h3 class="abstract">Abstract</h3>e academic and non-academic computer music contexts, using live coding as glue between them.   In this article, I will analyse live coding technique under the magnifying lens of Ethnography. Using this perspective, I will try to delve into three main aspects: the effect on the audience/performer interaction of the screen projection during performances; the relationship between “hacker’s ethic”, borrowing a Pekka Himanen’s definition, and live coders community; how some researchers are trying to establish contacts between formal and informal music milieu. In my view, an Ethnographical approach can help people interested in live coding to contextualise some implication of this technique’s internal dynamics. Additionally, this perspective can be useful to build a bridge between som</div><hr /><div id="paper66"><h2 class="title"> Patterns of User Experience in Performance Programming</h2><table class="authorlist"><tr><td>Alan Blackwell (University of Cambridge)</td></tr></table><h3 class="abstract">Abstract</h3>This paper presents a pattern language for user experiences in live coding. It uses a recently defined analytic framework that has developed out of the Cognitive Dimensions of Notations and related approaches. The focus on performance programming offers particular value in its potential to construct rigorous accounts of the experiences of both performers (the live coder) and audiences. Although developed as an account of live coding, the findings promise to be relevant to a wider range of performance programming contexts, which could benefit from analysis in terms of live coding, if a systematic framework of this kind were available. The paper provides a detailed analytic commentary, drawing on the broadly diverse body of prior live coding practice, but using music live coding as a central running example. The findings demonstrate the advantage of rigorous analysis from an independent theoretical perspective, and suggest the potential for future work that might draw on this pattern language as a basis for empirical investigations of user experience, and as a theoretical grounding in practice-led design of new live coding languages and tools.</div><hr /><div id="paper67"><h2 class="title"> Coda Lisa: Collaborative Art in the Browser</h2><table class="authorlist"><tr><td>Felienne Hermans (Delft University of Technology) and Rico Huijbers (Amazon Web Services)</td></tr></table><h3 class="abstract">Abstract</h3>This paper introduces Code Lisa: a collaborative programming environment
in the browser that allows users to program one cell in a grid of cells.
The cells can react to each other, but also to the environment,
represented by sensor values on an EV3 Lego Mindstorms robot. By
programming reactions to each other and to the sensors, a group of Coda
Lisa users can together create a living, interactive art work. Users
program the cells using JavaScript, and can experiment locally with
their cell in a live editor created for this purpose, which shows a
preview of the cell's behaviour. Once ready, the cell's program can be
submitted to the server so it can be rendered in the shared grid of
cells, by a second Coda Lisa client application: the viewer. In addition
to the implementation of Coda Lisa, this paper also describes several
plans for future development.
</div><hr /><div id="paper80"><h2 class="title"> Live Coding Through Rule-Based Modelling of High Level Structures: exploring output spaces of algorithmic composition systems</h2><table class="authorlist"><tr><td>Iván Paz (Barcelona Tech)</td></tr></table><h3 class="abstract">Abstract</h3>Live coding commonly takes pieces of code from algorithmic composition systems. However, sometimes algorithmic generators either do not consistently show high-level properties, like dramatic transition among parts, or simply, our aesthetic criterion prefers some particular cases among all the possible. In such cases it is useful to have tools for exploring the output space of generative systems, in order to identify and categorize outputs with specific properties. This paper presents an approach to creating linguistic rules out of human-evaluated patterns and their potential uses in live coding to create high-level structures. The methodology starts with a set of sampled examples from an algorithmic system that are evaluated by the user through qualitative linguistic variables. Then, the examples along with the user's evaluation are analysed through an inductive and rule extraction methodology. For a particular example case, these rules are extracted and evaluated. Its application then as information used for writing code on the fly, as well as its implementation in the form of filters or generators is presented.</div><hr /><div id="paper82"><h2 class="title"> What Does Live Coding Know?</h2><table class="authorlist"><tr><td>Geoff Cox (University of Aarhus)</td></tr></table><h3 class="abstract">Abstract</h3>Live coding can be seen to reflect contemporary conditions in which our lives seem to be increasingly determined by various scripts and computational processes. It demonstrates the possibility for more expansive ideas that emerge in the uncertainties of improvised performance. This paper further situates the practice of live coding in the context of artistic research and the notion of ‘onto-epistemology’. One of the challenges, it is argued, is to bring code back into the frame of ‘material-discursive’ practice so that code can be understood for what it is, how it is produced and what it might become. This is arguably the critical task of live coding: to expose the condition of possibility in this way; in other words, to remain attentive to the contradictions of what constitutes knowledge in contested fields of practice, and to demonstrate modes of uncertainty in what would otherwise seem to be determinate computational processes. </div><hr /><div id="paper87"><h2 class="title"> Live Coding/Weaving — Penelopean Mêtis and the Weaver-Coder’s Kairos</h2><table class="authorlist"><tr><td>Emma Cocker (Nottingham Trent University)</td></tr></table><h3 class="abstract">Abstract</h3>Drawing on my experience as a critical interlocutor within the Weaving Codes, Coding Weaves project (2014 — 2016, http://kairotic.org/), in this paper I propose potential points of connection between Ancient weaving and live coding, considering both practices through the prism of the Ancient Greek concept of technē, a species of tactical knowledge combining the principles of mêtis (cunning intelligence) and kairos (opportune timing). Specifically, this enquiry addresses the human qualities of attention, cognitive agility and tactical intelligence activated within both live coding and live weaving, arguing that such practices might have potential as ‘practices of the self’, as a means for cultivating a more critical mode of human agency and subjectivity. </div><hr /><div id="paper77"><h2 class="title"> Social Imagination</h2><table class="authorlist"><tr><td>Carolina Di Prospero (UNSAM)</td></tr></table><h3 class="abstract">Abstract</h3>This is a short paper that proposes an approach to the activity of live coding as an artistic configuration constituted in a creative practice from improvisation, openness and constant exploration. I just want to share some thoughts about sociability in live coding, in terms of “imagined community” (Anderson 1991) to address this collective aspect.
The approach is anthropological, through ethnographic field work from which the method seeks to explore some combination between a scope, actors and activities and a cut of reality that encompasses practices, values and formal rules. The aim of the ethnography is to address the distinction: “between the real and the ideal culture, between what people do and what people say they do, and hence between the field of practices, values and rules” (Guber 2001).
This work seeks to provide some characterization of a collective artistic expression in constant process, which mediates and constitutes sociability and subjectivities in a sociotechnical context.
</div><hr /><div id="paper74"><h2 class="title"> Materiality, Economy, Community: Hugh Davies’s Electronic Musical Instruments and their Relation to Present-Day Live Coding Practice</h2><table class="authorlist"><tr><td>James Mooney (University of Leeds)</td></tr></table><h3 class="abstract">Abstract</h3>The purpose of this paper is to present the self-built electroacoustic musical instruments of Hugh Davies (1943-2005) to the international live coding community, and to propose points of similarity between Davies’s practice and present-day live coding practice. In the first part of the paper, the context within which Davies’s instrument-building practice developed, in the late 1960s, is outlined, and a number of specific instruments are described. Aspects of Davies’s performance style, repertoire, and the ensembles with which he performed are discussed, as are activities such as instrument-building workshops and public exhibitions of instruments, in which he regularly participated. In the second part of the paper, four areas of connection with present-day live coding practice are suggested. Respectively, these focus upon live coding’s status: (1) as part of a long historic tradition of live electronic music performance (as opposed to electronic music constructed in the studio); (2) as a practice in which the performer him or herself builds the apparatus (whether physical or code-based) through which the music is mediated; (3) as an improvised or semi-improvised art-form in which music is developed in real time, within a framework bounded by material or quasi-material constraints; and (4) as a community of practice with a distinct agenda of promoting understanding through engagement. This paper is presented as a case study in exploring live coding’s historic precedents, and as a contribution toward situating live coding within a broader historical, cultural context.</div><hr /><div id="paper81"><h2 class="title"> Cognition and Improvisation: Some Implications for Live Coding</h2><table class="authorlist"><tr><td>Tim Sayer (University of St Mark and St John Plymouth)</td></tr></table><h3 class="abstract">Abstract</h3>This paper explores the perception that live coding is a “real-time” improvisatory activity. It posits the notion that because live coding requires less complex motor skills than instrumental improvisation it may be less susceptible to the influence of mechanical modes of musical expression. This hypothesis will explore the concept of goal states, models of memory and the function of reflexes and reactions as a means of mapping this territory and will provide a framework to understand the various perceptual domains with which a coder engages during a live extemporised performance. This exploration will engage in a comparative discourse relating live coding to instrumental improvisation, as a point of departure for the understanding of cognitive functioning in this rapidly developing performance paradigm.</div><hr /><div id="paper105"><h2 class="title"> From Live Coding to Virtual Being</h2><table class="authorlist"><tr><td>Nikolai Suslov (Fund for Supporting Development of Russian Technology) and Tatiana Soshenina (Moscow Institute of Architecture)</td></tr></table><h3 class="abstract">Abstract</h3>The self-explorative, collaborative environments and virtual worlds are setting up the new standards in software engineering for today. In this, live coding is also required in reviewing as for programmers and as for artists too. The most popular live coding frameworks, even being built by using highly dynamic, reflective languages, still suffer on tight bindings to single-node or client-server architecture, language or platform dependence and third-party tools. That leads to inability nor to develop nor scale to the Internet of things the new created works using live coding. In the paper we introduce the prototype of integration of object-oriented language for pattern matching OMeta onto Virtual World Framework on JavaScript. That integration will allow using the live coding in virtual worlds with user-defined languages. Also we explore the possibilities of a conformal scaling of live coding in the case of augmented reality systems and Internet of things. In summary, the paper describes the efforts being done for involving virtual worlds architecture in live coding process. All prototypes that are described in the paper are available for experimenting with on Krestianstvo SDK open source project: http://www.krestianstvo.org</div><hr />