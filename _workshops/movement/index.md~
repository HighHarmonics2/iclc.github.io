
## Livecoding relations between body movement and sound

* Marije Baalman, nescivi

Workshop on livecoding relationships between body movement and
sound. Using wireless sensors that capture movement of the body and
a data sharing network, the participants will engage in
collaboratively create mappings of sensor data to sonic or other
media output.

### Description

As (wireless) sensor interfaces become more and more available and
accessible to artists, the creation of the the relationships between
the data the sensors produce and the output in media has become more
and more a subject of research. Rather than fixed relationships or
mappings between sensor data and output media, livecoding can create a
dialog between all the performers in an interactive performance,
between the movement and the code, between the movers and the
coders. Even in preparation of interactive performances, livecoding as
a skill is very valuable in order to be able to quickly prototype
different approaches of mapping data, try them out, and evaluate their
artistic quality. The adaptations can range from changing of parameter
ranges, to rewriting the algorithms that establish rules for
mapping. As a mode of performance, this approach can enable a new form
of improvisation, creating a dialog between dancers and livecoders, as
the dancers adapt their movements based on the mappings to output
media that are created by the livecoders, and the livecoders who adapt
their code based on the movement of the dancers.

During the workshop we will collaboratively explore the livecoding of
such mappings, using a wireless sensor system (the Sense/Stage MiniBee
; [https://docs.sensestage.eu]), equipped with accelerometers and a
selected range of other body-based sensors, and a data sharing network
([https://github.com/sensestage/xosc]).

The workshop will start with an exploration of the framework within
which we will work, before going on to exploring body movements, the
sensor data this produces and strategies for mapping this data to
output media - mainly sound. While examples of algorithms will be
given in SuperCollider, for the experienced livecoder they should be
easy to translate into his or her preferred programming language, as
long as a quick access to incoming OSC data is available. The workshop
should end with a collaborative livecoding and movement session of all
participants.

### Participant requirements

* A laptop with the livecoding programming language that you are familiar with.
* The livecoding programming language should be capable of receiving (and sending) custom OSC messages.
* The laptop should have WiFi capabilities (or you should bring an ethernet cable).
* Participants with a background in movement (dance, theatre, etc) are also welcome - even if they may not be livecoders themselves, but are interested in the collaboration with livecoders.
